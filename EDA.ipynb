{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Startup Data (SaberFix)\n",
    "Exploring Data and Answering Business Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session is the entry point for all Spark functionality \n",
    "# Thorugh the Spark Session you are able to read data, \n",
    "# create DataFrames and transform it using Structured API's like pyspark.\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName(\"StriderTest\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Views for each data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Movies View Creation\n",
    "print(\"\\n ----> Movies View Creation\")\n",
    "movies_schema = \"TITLE STRING, DURATION_MINS FLOAT,ORIGINAL_LANGUAGE STRING,SIZE_MB DOUBLE\"\n",
    "\n",
    "df_movies = spark.read.option(\"header\",\"true\").schema(movies_schema).csv(\"data/movies.csv\")\n",
    "df_movies.printSchema()\n",
    "df_movies.show(5)\n",
    "df_movies.createOrReplaceTempView(\"movies\")\n",
    "\n",
    "### Users View Creation\n",
    "print(\"\\n ----> Users View Creation\")\n",
    "df_users = spark.read.option(\"header\",\"true\").csv(\"data/users.csv\")\n",
    "df_users.show(5)\n",
    "df_users.createOrReplaceTempView(\"users\")\n",
    "\n",
    "\n",
    "### Streams View Cration\n",
    "print(\"\\n ----> Streams View Creation\")\n",
    "streams_schema = \"MOVIE_TITLE STRING, USER_EMAIL STRING,SIZE_MB DOUBLE,START_AT STRING,END_AT STRING\"\n",
    "\n",
    "df_streams_1 = spark.read.option(\"header\",\"true\").schema(streams_schema).csv(\"data/streams.csv\")\n",
    "\n",
    "df_streams_2 = (df_streams_1 #### Transformation \n",
    ".withColumn('SIZE_MB', col('size_mb').astype(\"DOUBLE\")) \n",
    ".withColumn('START_AT', to_timestamp(col(\"start_at\"),\"yyyy-MM-dd'T'HH:mm:ss.SSSZZZ\")) \n",
    ".withColumn('END_AT', to_timestamp(col(\"end_at\"),\"yyyy-MM-dd'T'HH:mm:ss.SSSZZZ\"))\n",
    ")\n",
    "\n",
    "df_streams_2.printSchema()\n",
    "df_streams_2.show(5)\n",
    "df_streams_2.createOrReplaceTempView(\"streams\")\n",
    "\n",
    "\n",
    "### Authors View Creation\n",
    "print(\"\\n ----> Authors View Creation\")\n",
    "df_authors = spark.read.option(\"header\",\"true\").json(\"data/authors.json\")\n",
    "\n",
    "df_authors_2 = (df_authors # transform\n",
    ".withColumn('died_at', to_timestamp(col(\"died_at\"),\"yyyy-MM-dd'T'HH:mm:ss.SSSZZZ\"))\n",
    ") \n",
    "df_authors_2.show(5)\n",
    "df_authors_2.createOrReplaceTempView(\"authors\")\n",
    "\n",
    "\n",
    "### Books View Creation\n",
    "print(\"\\n ----> Books View Creation\")\n",
    "df_books = spark.read.option(\"header\",\"true\").json(\"data/books.json\")\n",
    "df_books.show(5)\n",
    "df_books.createOrReplaceTempView(\"books\")\n",
    "\n",
    "\n",
    "### Reviews View Creation\n",
    "print(\"\\n ----> Reviews View Creation\")\n",
    "df_reviews = spark.read.option(\"header\",\"true\").json(\"data/reviews.json\")\n",
    "df_reviews.show(5)\n",
    "df_reviews.createOrReplaceTempView(\"reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What percentage of the streamed movies are based on books?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_distinct_movies = spark.sql(\"select distinct MOVIE_TITLE as moviesCount from streams\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|reviewsBooksCount|\n",
      "+-----------------+\n",
      "|              102|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct book) as reviewsBooksCount from reviews\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9340659340659341"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q1 = \"\"\"\n",
    "SELECT m.title, r.movie\n",
    "FROM movies as m\n",
    "LEFT JOIN reviews as r on m.title = r.movie\n",
    "WHERE r.book is not null\n",
    "\"\"\"\n",
    "movies_based_on_books_on_sf = spark.sql(q1).distinct().count()\n",
    "movies_based_on_books_on_sf/sf_distinct_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many users were watching \"Unforgiven\" on Christmas morning (between 7 and 12 am on December 25)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q2 = \"\"\"\n",
    "SELECT START_AT\n",
    "FROM streams\n",
    "WHERE \n",
    "MOVIE_TITLE = 'Unforgiven'\n",
    "AND HOUR(START_AT) BETWEEN 7 AND 12 \n",
    "AND DATE(START_AT) = '2021-12-25'\n",
    "\"\"\"\n",
    "spark.sql(q2).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many movies based on books written by Singaporeans authors were streamed that month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q3 = \"\"\"\n",
    "SELECT distinct movie_title\n",
    "FROM streams as s\n",
    "LEFT JOIN reviews as r on s.MOVIE_TITLE = r.movie\n",
    "left join books b on r.book = b.name\n",
    "left join authors a on  b.author = a.name\n",
    "WHERE \n",
    "month(s.START_AT) = 12\n",
    "and year(s.START_AT) = 2021\n",
    "and a.nationality = 'Singaporeans'\n",
    "\"\"\"\n",
    "spark.sql(q3).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the average streaming duration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+\n",
      "|            START_AT|              END_AT|        diff|\n",
      "+--------------------+--------------------+------------+\n",
      "|2021-12-06 15:30:...|2021-12-07 11:44:...|20:14:19.078|\n",
      "|2021-12-15 00:36:...|2021-12-15 01:57:...|01:21:01.766|\n",
      "|2021-12-12 18:32:...|2021-12-13 16:37:...|22:05:31.779|\n",
      "|2021-12-04 16:47:...|2021-12-05 03:13:...|10:26:20.379|\n",
      "|2021-12-25 10:27:...|2021-12-25 20:22:...|09:55:40.465|\n",
      "|2021-12-26 21:13:...|2021-12-27 07:18:...|10:05:08.437|\n",
      "|2021-12-02 06:14:...|2021-12-03 03:15:...| 21:01:48.65|\n",
      "|2021-12-14 23:15:...|2021-12-15 08:08:...|08:52:19.761|\n",
      "|2021-12-14 02:47:...|2021-12-14 07:10:...|04:22:40.743|\n",
      "|2021-12-16 22:05:...|2021-12-17 03:51:...|05:46:00.433|\n",
      "|2021-12-22 03:29:...|2021-12-22 18:53:...|15:24:10.009|\n",
      "|2021-12-19 16:32:...|2021-12-20 10:27:...|17:54:48.671|\n",
      "|2021-12-19 17:31:...|2021-12-19 21:19:...|03:48:27.919|\n",
      "|2021-12-28 19:24:...|2021-12-28 19:26:...|00:01:27.272|\n",
      "|2021-12-21 16:46:...|2021-12-22 11:06:...|18:20:02.311|\n",
      "|2021-12-27 20:50:...|2021-12-28 02:18:...|05:28:00.873|\n",
      "|2021-12-28 02:49:...|2021-12-29 02:39:...|23:49:34.043|\n",
      "|2021-12-14 11:36:...|2021-12-15 07:45:...|20:09:19.394|\n",
      "|2021-12-05 10:00:...|2021-12-06 04:32:...|18:31:55.921|\n",
      "|2021-12-03 06:12:...|2021-12-03 15:01:...|08:48:39.011|\n",
      "|2021-12-22 03:56:...|2021-12-22 05:40:...|01:43:58.896|\n",
      "|2021-12-19 11:46:...|2021-12-20 10:42:...|22:55:58.782|\n",
      "|2021-12-05 03:11:...|2021-12-05 22:53:...|19:41:37.152|\n",
      "|2021-12-05 16:37:...|2021-12-06 04:27:...|11:50:06.391|\n",
      "|2021-12-09 11:34:...|2021-12-09 17:50:...|06:15:45.138|\n",
      "|2021-12-05 01:38:...|2021-12-05 05:45:...|04:07:12.139|\n",
      "|2021-12-04 01:59:...|2021-12-05 01:54:...|23:55:01.087|\n",
      "|2021-12-02 08:55:...|2021-12-02 10:37:...|01:42:36.689|\n",
      "|2021-12-27 12:18:...|2021-12-27 21:06:...|08:48:19.577|\n",
      "|2021-12-05 21:09:...|2021-12-06 13:41:...|16:32:04.818|\n",
      "|2021-12-24 04:32:...|2021-12-24 18:14:...|13:41:35.613|\n",
      "|2021-12-23 11:29:...|2021-12-23 13:26:...|01:56:33.123|\n",
      "|2021-12-05 00:26:...|2021-12-05 08:47:...| 08:21:18.93|\n",
      "|2021-12-07 06:39:...|2021-12-07 09:17:...|02:38:12.877|\n",
      "|2021-12-27 05:12:...|2021-12-27 17:15:...|12:02:43.661|\n",
      "|2021-12-01 21:27:...|2021-12-02 14:23:...| 16:56:01.49|\n",
      "|2021-12-11 14:48:...|2021-12-12 10:37:...|19:49:12.895|\n",
      "|2021-12-12 06:31:...|2021-12-12 10:41:...|04:10:28.786|\n",
      "|2021-12-27 20:18:...|2021-12-27 21:25:...|01:06:40.375|\n",
      "|2021-12-23 10:12:...|2021-12-23 19:03:...|08:51:19.224|\n",
      "|2021-12-30 07:18:...|2021-12-30 22:59:...| 15:41:09.13|\n",
      "|2021-12-03 23:42:...|2021-12-04 10:50:...|11:07:19.782|\n",
      "|2021-12-22 08:25:...|2021-12-22 10:11:...|01:45:44.564|\n",
      "|2021-12-23 06:55:...|2021-12-23 22:58:...| 16:03:03.64|\n",
      "|2021-12-17 07:20:...|2021-12-18 06:07:...|22:46:25.822|\n",
      "|2021-12-07 21:58:...|2021-12-08 01:11:...| 03:13:40.46|\n",
      "|2021-12-21 01:42:...|2021-12-21 09:53:...|08:11:00.938|\n",
      "|2021-12-23 05:20:...|2021-12-23 23:53:...|18:33:49.268|\n",
      "|2021-12-19 23:12:...|2021-12-20 07:52:...|08:39:56.361|\n",
      "|2021-12-15 09:32:...|2021-12-16 01:41:...|16:09:16.858|\n",
      "|2021-12-15 20:27:...|2021-12-16 00:07:...|03:39:47.193|\n",
      "|2021-12-11 05:42:...|2021-12-12 04:34:...|22:52:31.944|\n",
      "|2021-12-16 16:07:...|2021-12-17 13:01:...|20:53:56.245|\n",
      "|2021-12-24 19:07:...|2021-12-25 17:16:...|22:08:37.283|\n",
      "|2021-12-08 18:54:...|2021-12-09 16:34:...|  21:40:15.3|\n",
      "|2021-12-11 13:13:...|2021-12-12 08:42:...|19:29:03.451|\n",
      "|2021-12-03 13:04:...|2021-12-04 00:30:...|11:25:23.657|\n",
      "|2021-12-24 05:15:...|2021-12-24 11:44:...|06:28:53.568|\n",
      "|2021-12-18 06:12:...|2021-12-19 02:54:...|20:41:13.642|\n",
      "|2021-12-19 02:40:...|2021-12-20 02:23:...| 23:42:40.58|\n",
      "|2021-12-20 13:11:...|2021-12-21 05:00:...|15:49:01.338|\n",
      "|2021-12-03 13:07:...|2021-12-04 08:11:...| 19:03:49.37|\n",
      "|2021-12-13 21:19:...|2021-12-14 12:48:...|15:29:10.069|\n",
      "|2021-12-22 23:06:...|2021-12-23 08:51:...|09:45:11.986|\n",
      "|2021-12-28 10:57:...|2021-12-29 10:48:...|23:50:54.687|\n",
      "|2021-12-21 17:16:...|2021-12-22 00:30:...|07:14:38.408|\n",
      "|2021-12-20 01:11:...|2021-12-20 08:35:...|07:23:30.976|\n",
      "|2021-12-28 19:35:...|2021-12-29 12:27:...|16:52:25.598|\n",
      "|2021-11-30 21:05:...|2021-11-30 23:11:...|02:05:46.289|\n",
      "|2021-12-05 21:45:...|2021-12-06 05:32:...| 07:47:22.58|\n",
      "|2021-12-25 10:02:...|2021-12-26 01:40:...|15:37:22.906|\n",
      "|2021-12-25 10:17:...|2021-12-25 11:58:...| 01:41:11.22|\n",
      "|2021-12-15 00:47:...|2021-12-15 15:44:...|14:56:58.137|\n",
      "|2021-12-26 06:31:...|2021-12-27 03:55:...|21:23:05.965|\n",
      "|2021-12-30 00:01:...|2021-12-30 15:50:...| 15:48:20.67|\n",
      "|2021-12-05 20:34:...|2021-12-05 21:09:...|00:34:25.181|\n",
      "|2021-12-16 08:56:...|2021-12-16 22:16:...|13:20:37.848|\n",
      "|2021-12-08 20:20:...|2021-12-09 14:22:...|18:02:10.775|\n",
      "|2021-12-05 18:42:...|2021-12-06 02:41:...|07:58:59.037|\n",
      "|2021-12-02 10:00:...|2021-12-03 03:29:...|17:29:00.434|\n",
      "|2021-12-03 12:56:...|2021-12-04 03:49:...|14:53:31.717|\n",
      "|2021-12-14 16:57:...|2021-12-14 23:53:...|06:56:30.039|\n",
      "|2021-12-29 01:32:...|2021-12-29 17:35:...|16:03:23.191|\n",
      "|2021-12-10 04:52:...|2021-12-10 09:00:...|04:08:28.503|\n",
      "|2021-12-03 14:49:...|2021-12-04 06:51:...|16:02:12.267|\n",
      "|2021-12-25 18:43:...|2021-12-26 01:10:...|06:27:30.436|\n",
      "|2021-12-14 04:29:...|2021-12-15 02:47:...|22:18:06.565|\n",
      "|2021-12-28 20:30:...|2021-12-29 04:08:...|07:37:56.669|\n",
      "|2021-12-18 20:03:...|2021-12-18 21:09:...|01:06:29.858|\n",
      "|2021-12-04 10:11:...|2021-12-05 01:08:...| 14:57:28.54|\n",
      "|2021-12-20 17:41:...|2021-12-20 21:00:...|03:18:20.174|\n",
      "|2021-12-05 17:01:...|2021-12-06 16:24:...|23:23:30.976|\n",
      "|2021-12-14 03:44:...|2021-12-14 10:35:...|06:50:47.123|\n",
      "|2021-12-18 06:37:...|2021-12-18 20:49:...|14:11:54.789|\n",
      "|2021-12-15 09:46:...|2021-12-15 12:45:...|02:59:00.935|\n",
      "|2021-12-08 12:38:...|2021-12-08 13:51:...|01:13:13.093|\n",
      "|2021-12-29 06:24:...|2021-12-30 04:31:...|22:06:55.372|\n",
      "|2021-12-04 02:05:...|2021-12-04 22:39:...|20:34:05.794|\n",
      "|2021-12-30 14:48:...|2021-12-31 00:18:...|09:30:00.433|\n",
      "|2021-12-16 13:59:...|2021-12-17 13:57:...|23:57:47.244|\n",
      "+--------------------+--------------------+------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q4 = \"\"\"\n",
    "SELECT START_AT, END_AT, replace(split((END_AT - START_AT),' ')[2],\"'\",\"\") diff\n",
    "FROM streams \n",
    "\"\"\"\n",
    "spark.sql(q4).show(100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
