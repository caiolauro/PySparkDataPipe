{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session is the entry point for all Spark functionality \n",
    "# Thorugh the Spark Session you are able to read data, \n",
    "# create DataFrames and transform it using Structured API's like pyspark.\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName(\"tsTest\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----> Movies View Creation\n",
      "root\n",
      " |-- TITLE: string (nullable = true)\n",
      " |-- DURATION_MINS: float (nullable = true)\n",
      " |-- ORIGINAL_LANGUAGE: string (nullable = true)\n",
      " |-- SIZE_MB: double (nullable = true)\n",
      "\n",
      "+----------------+-------------+-----------------+-------+\n",
      "|           TITLE|DURATION_MINS|ORIGINAL_LANGUAGE|SIZE_MB|\n",
      "+----------------+-------------+-----------------+-------+\n",
      "|The Great Escape|        113.0|           Korean|  876.0|\n",
      "|   The Third Man|        129.0|           French| 1857.0|\n",
      "| Cinema Paradiso|        102.0|          Russian|  676.0|\n",
      "|        Scarface|        112.0|         Japanese| 1236.0|\n",
      "|         Vertigo|        146.0|          Italian|  649.0|\n",
      "+----------------+-------------+-----------------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " ----> Users View Creation\n",
      "+----------+---------+--------------------+\n",
      "|first_name|last_name|               email|\n",
      "+----------+---------+--------------------+\n",
      "|      Eddy|   Kirlin|karine@bode-rogah...|\n",
      "|     Elvia|     Conn|janet_haag@crist.biz|\n",
      "|   Ezekiel|    Block|    landon@bauch.org|\n",
      "|      Hugh| Nikolaus|grover_terry@metz...|\n",
      "|      Iona|    Huels|  clelia@wuckert.com|\n",
      "+----------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " ----> Streams View Creation\n",
      "root\n",
      " |-- MOVIE_TITLE: string (nullable = true)\n",
      " |-- USER_EMAIL: string (nullable = true)\n",
      " |-- SIZE_MB: double (nullable = true)\n",
      " |-- START_AT: timestamp (nullable = true)\n",
      " |-- END_AT: timestamp (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+------------------+--------------------+--------------------+\n",
      "|         MOVIE_TITLE|          USER_EMAIL|           SIZE_MB|            START_AT|              END_AT|\n",
      "+--------------------+--------------------+------------------+--------------------+--------------------+\n",
      "|   Full Metal Jacket|rodrick_bergnaum@...| 613.4245936603365|2021-12-06 15:30:...|2021-12-07 11:44:...|\n",
      "|                Rush|nolan.wintheiser@...|  330.524118447188|2021-12-15 00:36:...|2021-12-15 01:57:...|\n",
      "|Star Wars: Episod...|willie.baumbach@d...| 2101.559005489579|2021-12-12 18:32:...|2021-12-13 16:37:...|\n",
      "|The Bridge on the...|catalina_rath@jon...|1988.0439476360807|2021-12-04 16:47:...|2021-12-05 03:13:...|\n",
      "|            3 Idiots|lowell.keeling@be...| 625.9428853440369|2021-12-25 10:27:...|2021-12-25 20:22:...|\n",
      "+--------------------+--------------------+------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " ----> Authors View Creation\n",
      "+--------------------+-------------------+--------------+-----------------+\n",
      "|          birth_date|            died_at|          name|      nationality|\n",
      "+--------------------+-------------------+--------------+-----------------+\n",
      "|1956-05-07T00:00:...|               null| Josh Johnston|Guianese (French)|\n",
      "|2000-06-30T00:00:...|2042-08-06 21:00:00|     Al Hamill|        Armenians|\n",
      "|1975-12-07T00:00:...|2049-02-23 21:00:00|Wilmer Reichel|        Andorrans|\n",
      "|1930-07-14T00:00:...|1982-04-13 21:00:00| Garland Lynch|     Singaporeans|\n",
      "|1967-02-25T00:00:...|1993-12-31 22:00:00|Napoleon Terry|          Kenyans|\n",
      "+--------------------+-------------------+--------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " ----> Books View Creation\n",
      "+--------------------+--------------------+-----+-------------------+\n",
      "|              author|                name|pages|          publisher|\n",
      "+--------------------+--------------------+-----+-------------------+\n",
      "|    Ms. Dorsey Grant|    An Evil Cradling| 6302|Harcourt Assessment|\n",
      "|     Alexa Dickinson|      As I Lay Dying| 8934|     Pavilion Books|\n",
      "|  Eneida Considine V|    Recalled to Life| 8195| Sidgwick & Jackson|\n",
      "|       Darcie Abbott|      The Waste Land| 8608|     Left Book Club|\n",
      "|Salvatore Herman PhD|Bury My Heart at ...| 6376|        Cisco Press|\n",
      "+--------------------+--------------------+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      " ----> Reviews View Creation\n",
      "+------------------+--------------------+----+--------------------+\n",
      "|              book|               movie|rate|              resume|\n",
      "+------------------+--------------------+----+--------------------+\n",
      "|A Passage to India|Beauty and the Beast|   1|Solitudo magnam v...|\n",
      "|    The Man Within|Star Wars: Episod...|   5|Adhuc ad velum. C...|\n",
      "|       Vanity Fair|    The Big Lebowski|   1|Tersus velit asse...|\n",
      "|The Moving Toyshop|        Mary and Max|   5|Pecco quis magni....|\n",
      "|     Endless Night|   L.A. Confidential|   3|Tyrannus audio au...|\n",
      "+------------------+--------------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Movies View Creation\n",
    "print(\"\\n ----> Movies View Creation\")\n",
    "movies_schema = \"TITLE STRING, DURATION_MINS FLOAT,ORIGINAL_LANGUAGE STRING,SIZE_MB DOUBLE\"\n",
    "\n",
    "df_movies = spark.read.option(\"header\",\"true\").schema(movies_schema).csv(\"data-dump/movies.csv\")\n",
    "df_movies.printSchema()\n",
    "df_movies.show(5)\n",
    "df_movies.createOrReplaceTempView(\"movies\")\n",
    "\n",
    "### Users View Creation\n",
    "print(\"\\n ----> Users View Creation\")\n",
    "df_users = spark.read.option(\"header\",\"true\").csv(\"data-dump/users.csv\")\n",
    "df_users.show(5)\n",
    "df_users.createOrReplaceTempView(\"users\")\n",
    "\n",
    "\n",
    "### Streams View Cration\n",
    "print(\"\\n ----> Streams View Creation\")\n",
    "streams_schema = \"MOVIE_TITLE STRING, USER_EMAIL STRING,SIZE_MB DOUBLE,START_AT STRING,END_AT STRING\"\n",
    "\n",
    "df_streams_1 = spark.read.option(\"header\",\"true\").schema(streams_schema).csv(\"data-dump/streams.csv\")\n",
    "\n",
    "df_streams_2 = (df_streams_1 #### Transformation \n",
    ".withColumn('SIZE_MB', col('size_mb').astype(\"DOUBLE\")) \n",
    ".withColumn('START_AT', to_timestamp(col(\"start_at\"),\"yyyy-MM-dd'T'HH:mm:ss.SSSZZZ\")) \n",
    ".withColumn('END_AT', to_timestamp(col(\"end_at\"),\"yyyy-MM-dd'T'HH:mm:ss.SSSZZZ\"))\n",
    ")\n",
    "\n",
    "df_streams_2.printSchema()\n",
    "df_streams_2.show(5)\n",
    "df_streams_2.createOrReplaceTempView(\"streams\")\n",
    "\n",
    "\n",
    "### Authors View Creation\n",
    "print(\"\\n ----> Authors View Creation\")\n",
    "df_authors = spark.read.option(\"header\",\"true\").json(\"data-dump/authors.json\")\n",
    "\n",
    "df_authors_2 = (df_authors # transform\n",
    ".withColumn('died_at', to_timestamp(col(\"died_at\"),\"yyyy-MM-dd'T'HH:mm:ss.SSSZZZ\"))\n",
    ") \n",
    "df_authors_2.show(5)\n",
    "df_authors_2.createOrReplaceTempView(\"authors\")\n",
    "\n",
    "\n",
    "### Books View Creation\n",
    "print(\"\\n ----> Books View Creation\")\n",
    "df_books = spark.read.option(\"header\",\"true\").json(\"data-dump/books.json\")\n",
    "df_books.show(5)\n",
    "df_books.createOrReplaceTempView(\"books\")\n",
    "\n",
    "\n",
    "### Reviews View Creation\n",
    "print(\"\\n ----> Reviews View Creation\")\n",
    "df_reviews = spark.read.option(\"header\",\"true\").json(\"data-dump/reviews.json\")\n",
    "df_reviews.show(5)\n",
    "df_reviews.createOrReplaceTempView(\"reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What percentage of the streamed movies are based on books?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_distinct_movies = spark.sql(\"select distinct MOVIE_TITLE as moviesCount from streams\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|reviewsBooksCount|\n",
      "+-----------------+\n",
      "|              102|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct book) as reviewsBooksCount from reviews\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9340659340659341"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = \"\"\"\n",
    "SELECT m.title, r.movie\n",
    "FROM movies as m\n",
    "LEFT JOIN reviews as r on m.title = r.movie\n",
    "WHERE r.book is not null\n",
    "\"\"\"\n",
    "movies_based_on_books_on_sf = spark.sql(q1).distinct().count()\n",
    "movies_based_on_books_on_sf/sf_distinct_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many users were watching \"Unforgiven\" on Christmas morning (between 7 and 12 am on December 25)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2 = \"\"\"\n",
    "SELECT START_AT\n",
    "FROM streams\n",
    "WHERE \n",
    "MOVIE_TITLE = 'Unforgiven'\n",
    "AND HOUR(START_AT) BETWEEN 7 AND 12 \n",
    "AND DATE(START_AT) = '2021-12-25'\n",
    "\"\"\"\n",
    "spark.sql(q2).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many movies based on books written by Singaporeans authors were streamed that month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = \"\"\"\n",
    "SELECT distinct movie_title\n",
    "FROM streams as s\n",
    "LEFT JOIN reviews as r on s.MOVIE_TITLE = r.movie\n",
    "left join books b on r.book = b.name\n",
    "left join authors a on  b.author = a.name\n",
    "WHERE \n",
    "month(s.START_AT) = 12\n",
    "and year(s.START_AT) = 2021\n",
    "and a.nationality = 'Singaporeans'\n",
    "\"\"\"\n",
    "spark.sql(q3).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the average streaming duration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|avg_streaming_duration|\n",
      "+----------------------+\n",
      "|    12.041684094613812|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q4 = \"\"\"\n",
    "WITH \n",
    "duration as\n",
    "(\n",
    "SELECT (replace(split((END_AT - START_AT),' ')[2],\"'\",\"\")) diff\n",
    "FROM streams \n",
    "WHERE\n",
    "month(start_at) = 12\n",
    "),\n",
    "duration_timed as\n",
    "(SELECT \n",
    "         AVG(HOUR(DIFF)) * 60 *60 as hour_avg_in_seconds\n",
    "        ,AVG(MINUTE(DIFF)) * 60 as minute_avg_in_seconds\n",
    "        ,AVG(SECOND(DIFF)) as second_avg_in_seconds\n",
    "FROM duration )\n",
    "\n",
    "SELECT ((hour_avg_in_seconds / 3600) + (minute_avg_in_seconds / 3600) + second_avg_in_seconds / 3600) as avg_streaming_duration\n",
    "FROM duration_timed\n",
    "\"\"\"\n",
    "spark.sql(q4).show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's the median streaming size in gigabytes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|size_in_mb_median|\n",
      "+-----------------+\n",
      "|  935.43929651322|\n",
      "+-----------------+\n",
      "\n",
      "+-------+------------+--------------------+-------------------+\n",
      "|summary| MOVIE_TITLE|          USER_EMAIL|            SIZE_MB|\n",
      "+-------+------------+--------------------+-------------------+\n",
      "|  count|        9652|                9652|               9652|\n",
      "|   mean|        null|                null| 1122.7224951748287|\n",
      "| stddev|        null|                null|   824.739344337668|\n",
      "|    min|12 Angry Men|abdul.casper@hage...|0.13392509085694668|\n",
      "|    max|      WALLÂ·E|zana_leffler@powl...|  3783.921923474418|\n",
      "+-------+------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q5 = \"\"\"\n",
    "select  percentile_approx(size_mb, 0.5) as size_in_mb_median\n",
    "from streams\n",
    "\"\"\"\n",
    "\n",
    "q6 = \"\"\"\n",
    "select *\n",
    "from streams\n",
    "\"\"\"\n",
    "spark.sql(q5).show()\n",
    "spark.sql(q6).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many users watched at least 50% of any movie in the last week of the month (7 days)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|users_above_50_percent|\n",
      "+----------------------+\n",
      "|                    65|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q7 = \"\"\"\n",
    " \n",
    "with \n",
    "stream_duration as\n",
    "(\n",
    "select \n",
    "s.*\n",
    ", (\n",
    "  hour(replace(split((END_AT - START_AT),' ')[2],\"'\",\"\"))*60 \n",
    "+ minute(replace(split((END_AT - START_AT),' ')[2],\"'\",\"\")) \n",
    "+ second(replace(split((END_AT - START_AT),' ')[2],\"'\",\"\"))/60\n",
    "\n",
    ")\n",
    " duration\n",
    "from streams s\n",
    "where\n",
    "month(start_at) = 12\n",
    "and day(start_at) between 25 and 31\n",
    "),\n",
    "user_duration as \n",
    "(select user_email, date(start_at),weekofyear(start_at), duration/duration_mins as rate\n",
    "from stream_duration sd\n",
    "left join movies m on sd.movie_title = m.title\n",
    "--where user_email like '%rodrick_bergnaum%'\n",
    ")\n",
    "select count(distinct user_email) as users_above_50_percent from user_duration where rate between 0.5 and 1\n",
    "\"\"\"\n",
    "spark.sql(q7).show(100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
